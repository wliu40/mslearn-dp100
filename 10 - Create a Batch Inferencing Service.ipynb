{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create a Batch Inferencing Service\n",
    "\n",
    "Imagine a health clinic takes patient measurements all day, saving the details for each patient in a separate file. Then overnight, the diabetes prediction model can be used to process all of the day's patient data as a batch, generating predictions that will be waiting the following morning so that the clinic can follow up with patients who are predicted to be at risk of diabetes. With Azure Machine Learning, you can accomplish this by creating a *batch inferencing pipeline*; and that's what you'll implement in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "To get started, connect to your workspace.\n",
    "\n",
    "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1649367713992
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.48.0 to work with myworkspace\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and register a model\n",
    "\n",
    "Now let's train and register a model to deploy in a batch inferencing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: mslearn-train-diabetes\n",
      "Loading Data...\n",
      "Training a decision tree model\n",
      "Accuracy: 0.8926666666666667\n",
      "AUC: 0.8803323548435243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_6812\\2140859650.py:34: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  run.log('Accuracy', np.float(acc))\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_6812\\2140859650.py:40: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  run.log('AUC', np.float(auc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace=ws, name='mslearn-train-diabetes')\n",
    "run = experiment.start_logging()\n",
    "print(\"Starting experiment:\", experiment.name)\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()\n",
    "\n",
    "# Register the model\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'Training context':'Inline Training'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "print('Model trained and registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and upload batch data\n",
    "\n",
    "Since we don't actually have a fully staffed clinic with patients from whom to get new data for this exercise, you'll generate a random sample from our diabetes CSV file, upload that data to a datastore in the Azure Machine Learning workspace, and register a dataset for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml_globaldatasets - Default = False\n",
      "data - Default = False\n",
      "workspaceworkingdirectory - Default = False\n",
      "workspaceartifactstore - Default = False\n",
      "workspacefilestore - Default = False\n",
      "workspaceblobstore - Default = True\n",
      "Folder created!\n",
      "Saving files...\n",
      "files saved!\n",
      "Uploading files to datastore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 100 files\n",
      "Uploading batch-data\\1.csv\n",
      "Uploaded batch-data\\1.csv, 1 files out of an estimated total of 100\n",
      "Uploading batch-data\\11.csv\n",
      "Uploaded batch-data\\11.csv, 2 files out of an estimated total of 100\n",
      "Uploading batch-data\\12.csv\n",
      "Uploaded batch-data\\12.csv, 3 files out of an estimated total of 100\n",
      "Uploading batch-data\\14.csv\n",
      "Uploaded batch-data\\14.csv, 4 files out of an estimated total of 100\n",
      "Uploading batch-data\\16.csv\n",
      "Uploaded batch-data\\16.csv, 5 files out of an estimated total of 100\n",
      "Uploading batch-data\\10.csv\n",
      "Uploaded batch-data\\10.csv, 6 files out of an estimated total of 100\n",
      "Uploading batch-data\\100.csv\n",
      "Uploaded batch-data\\100.csv, 7 files out of an estimated total of 100\n",
      "Uploading batch-data\\13.csv\n",
      "Uploaded batch-data\\13.csv, 8 files out of an estimated total of 100\n",
      "Uploading batch-data\\15.csv\n",
      "Uploaded batch-data\\15.csv, 9 files out of an estimated total of 100\n",
      "Uploading batch-data\\17.csv\n",
      "Uploaded batch-data\\17.csv, 10 files out of an estimated total of 100\n",
      "Uploading batch-data\\18.csv\n",
      "Uploaded batch-data\\18.csv, 11 files out of an estimated total of 100\n",
      "Uploading batch-data\\19.csv\n",
      "Uploaded batch-data\\19.csv, 12 files out of an estimated total of 100\n",
      "Uploading batch-data\\2.csv\n",
      "Uploaded batch-data\\2.csv, 13 files out of an estimated total of 100\n",
      "Uploading batch-data\\20.csv\n",
      "Uploaded batch-data\\20.csv, 14 files out of an estimated total of 100\n",
      "Uploading batch-data\\21.csv\n",
      "Uploaded batch-data\\21.csv, 15 files out of an estimated total of 100\n",
      "Uploading batch-data\\22.csv\n",
      "Uploaded batch-data\\22.csv, 16 files out of an estimated total of 100\n",
      "Uploading batch-data\\23.csv\n",
      "Uploaded batch-data\\23.csv, 17 files out of an estimated total of 100\n",
      "Uploading batch-data\\24.csv\n",
      "Uploaded batch-data\\24.csv, 18 files out of an estimated total of 100\n",
      "Uploading batch-data\\25.csv\n",
      "Uploaded batch-data\\25.csv, 19 files out of an estimated total of 100\n",
      "Uploading batch-data\\26.csv\n",
      "Uploaded batch-data\\26.csv, 20 files out of an estimated total of 100\n",
      "Uploading batch-data\\27.csv\n",
      "Uploaded batch-data\\27.csv, 21 files out of an estimated total of 100\n",
      "Uploading batch-data\\28.csv\n",
      "Uploaded batch-data\\28.csv, 22 files out of an estimated total of 100\n",
      "Uploading batch-data\\29.csv\n",
      "Uploaded batch-data\\29.csv, 23 files out of an estimated total of 100\n",
      "Uploading batch-data\\3.csv\n",
      "Uploaded batch-data\\3.csv, 24 files out of an estimated total of 100\n",
      "Uploading batch-data\\30.csv\n",
      "Uploaded batch-data\\30.csv, 25 files out of an estimated total of 100\n",
      "Uploading batch-data\\31.csv\n",
      "Uploaded batch-data\\31.csv, 26 files out of an estimated total of 100\n",
      "Uploading batch-data\\32.csv\n",
      "Uploaded batch-data\\32.csv, 27 files out of an estimated total of 100\n",
      "Uploading batch-data\\33.csv\n",
      "Uploaded batch-data\\33.csv, 28 files out of an estimated total of 100\n",
      "Uploading batch-data\\35.csv\n",
      "Uploaded batch-data\\35.csv, 29 files out of an estimated total of 100\n",
      "Uploading batch-data\\36.csv\n",
      "Uploaded batch-data\\36.csv, 30 files out of an estimated total of 100\n",
      "Uploading batch-data\\37.csv\n",
      "Uploaded batch-data\\37.csv, 31 files out of an estimated total of 100\n",
      "Uploading batch-data\\38.csv\n",
      "Uploaded batch-data\\38.csv, 32 files out of an estimated total of 100\n",
      "Uploading batch-data\\39.csv\n",
      "Uploaded batch-data\\39.csv, 33 files out of an estimated total of 100\n",
      "Uploading batch-data\\4.csv\n",
      "Uploaded batch-data\\4.csv, 34 files out of an estimated total of 100\n",
      "Uploading batch-data\\40.csv\n",
      "Uploaded batch-data\\40.csv, 35 files out of an estimated total of 100\n",
      "Uploading batch-data\\41.csv\n",
      "Uploaded batch-data\\41.csv, 36 files out of an estimated total of 100\n",
      "Uploading batch-data\\42.csv\n",
      "Uploaded batch-data\\42.csv, 37 files out of an estimated total of 100\n",
      "Uploading batch-data\\43.csv\n",
      "Uploaded batch-data\\43.csv, 38 files out of an estimated total of 100\n",
      "Uploading batch-data\\44.csv\n",
      "Uploaded batch-data\\44.csv, 39 files out of an estimated total of 100\n",
      "Uploading batch-data\\45.csv\n",
      "Uploaded batch-data\\45.csv, 40 files out of an estimated total of 100\n",
      "Uploading batch-data\\46.csv\n",
      "Uploaded batch-data\\46.csv, 41 files out of an estimated total of 100\n",
      "Uploading batch-data\\47.csv\n",
      "Uploaded batch-data\\47.csv, 42 files out of an estimated total of 100\n",
      "Uploading batch-data\\48.csv\n",
      "Uploaded batch-data\\48.csv, 43 files out of an estimated total of 100\n",
      "Uploading batch-data\\49.csv\n",
      "Uploaded batch-data\\49.csv, 44 files out of an estimated total of 100\n",
      "Uploading batch-data\\5.csv\n",
      "Uploaded batch-data\\5.csv, 45 files out of an estimated total of 100\n",
      "Uploading batch-data\\50.csv\n",
      "Uploaded batch-data\\50.csv, 46 files out of an estimated total of 100\n",
      "Uploading batch-data\\51.csv\n",
      "Uploaded batch-data\\51.csv, 47 files out of an estimated total of 100\n",
      "Uploading batch-data\\52.csv\n",
      "Uploaded batch-data\\52.csv, 48 files out of an estimated total of 100\n",
      "Uploading batch-data\\53.csv\n",
      "Uploaded batch-data\\53.csv, 49 files out of an estimated total of 100\n",
      "Uploading batch-data\\54.csv\n",
      "Uploaded batch-data\\54.csv, 50 files out of an estimated total of 100\n",
      "Uploading batch-data\\55.csv\n",
      "Uploaded batch-data\\55.csv, 51 files out of an estimated total of 100\n",
      "Uploading batch-data\\56.csv\n",
      "Uploaded batch-data\\56.csv, 52 files out of an estimated total of 100\n",
      "Uploading batch-data\\57.csv\n",
      "Uploaded batch-data\\57.csv, 53 files out of an estimated total of 100\n",
      "Uploading batch-data\\58.csv\n",
      "Uploaded batch-data\\58.csv, 54 files out of an estimated total of 100\n",
      "Uploading batch-data\\59.csv\n",
      "Uploaded batch-data\\59.csv, 55 files out of an estimated total of 100\n",
      "Uploading batch-data\\6.csv\n",
      "Uploaded batch-data\\6.csv, 56 files out of an estimated total of 100\n",
      "Uploading batch-data\\60.csv\n",
      "Uploaded batch-data\\60.csv, 57 files out of an estimated total of 100\n",
      "Uploading batch-data\\61.csv\n",
      "Uploaded batch-data\\61.csv, 58 files out of an estimated total of 100\n",
      "Uploading batch-data\\62.csv\n",
      "Uploaded batch-data\\62.csv, 59 files out of an estimated total of 100\n",
      "Uploading batch-data\\63.csv\n",
      "Uploaded batch-data\\63.csv, 60 files out of an estimated total of 100\n",
      "Uploading batch-data\\64.csv\n",
      "Uploaded batch-data\\64.csv, 61 files out of an estimated total of 100\n",
      "Uploading batch-data\\65.csv\n",
      "Uploaded batch-data\\65.csv, 62 files out of an estimated total of 100\n",
      "Uploading batch-data\\66.csv\n",
      "Uploaded batch-data\\66.csv, 63 files out of an estimated total of 100\n",
      "Uploading batch-data\\67.csv\n",
      "Uploaded batch-data\\67.csv, 64 files out of an estimated total of 100\n",
      "Uploading batch-data\\68.csv\n",
      "Uploaded batch-data\\68.csv, 65 files out of an estimated total of 100\n",
      "Uploading batch-data\\69.csv\n",
      "Uploaded batch-data\\69.csv, 66 files out of an estimated total of 100\n",
      "Uploading batch-data\\7.csv\n",
      "Uploaded batch-data\\7.csv, 67 files out of an estimated total of 100\n",
      "Uploading batch-data\\34.csv\n",
      "Uploaded batch-data\\34.csv, 68 files out of an estimated total of 100\n",
      "Uploading batch-data\\70.csv\n",
      "Uploaded batch-data\\70.csv, 69 files out of an estimated total of 100\n",
      "Uploading batch-data\\71.csv\n",
      "Uploaded batch-data\\71.csv, 70 files out of an estimated total of 100\n",
      "Uploading batch-data\\72.csv\n",
      "Uploaded batch-data\\72.csv, 71 files out of an estimated total of 100\n",
      "Uploading batch-data\\73.csv\n",
      "Uploaded batch-data\\73.csv, 72 files out of an estimated total of 100\n",
      "Uploading batch-data\\74.csv\n",
      "Uploaded batch-data\\74.csv, 73 files out of an estimated total of 100\n",
      "Uploading batch-data\\75.csv\n",
      "Uploaded batch-data\\75.csv, 74 files out of an estimated total of 100\n",
      "Uploading batch-data\\76.csv\n",
      "Uploaded batch-data\\76.csv, 75 files out of an estimated total of 100\n",
      "Uploading batch-data\\77.csv\n",
      "Uploaded batch-data\\77.csv, 76 files out of an estimated total of 100\n",
      "Uploading batch-data\\78.csv\n",
      "Uploaded batch-data\\78.csv, 77 files out of an estimated total of 100\n",
      "Uploading batch-data\\79.csv\n",
      "Uploaded batch-data\\79.csv, 78 files out of an estimated total of 100\n",
      "Uploading batch-data\\8.csv\n",
      "Uploaded batch-data\\8.csv, 79 files out of an estimated total of 100\n",
      "Uploading batch-data\\80.csv\n",
      "Uploaded batch-data\\80.csv, 80 files out of an estimated total of 100\n",
      "Uploading batch-data\\81.csv\n",
      "Uploaded batch-data\\81.csv, 81 files out of an estimated total of 100\n",
      "Uploading batch-data\\82.csv\n",
      "Uploaded batch-data\\82.csv, 82 files out of an estimated total of 100\n",
      "Uploading batch-data\\83.csv\n",
      "Uploaded batch-data\\83.csv, 83 files out of an estimated total of 100\n",
      "Uploading batch-data\\84.csv\n",
      "Uploaded batch-data\\84.csv, 84 files out of an estimated total of 100\n",
      "Uploading batch-data\\85.csv\n",
      "Uploaded batch-data\\85.csv, 85 files out of an estimated total of 100\n",
      "Uploading batch-data\\86.csv\n",
      "Uploaded batch-data\\86.csv, 86 files out of an estimated total of 100\n",
      "Uploading batch-data\\87.csv\n",
      "Uploaded batch-data\\87.csv, 87 files out of an estimated total of 100\n",
      "Uploading batch-data\\88.csv\n",
      "Uploaded batch-data\\88.csv, 88 files out of an estimated total of 100\n",
      "Uploading batch-data\\89.csv\n",
      "Uploaded batch-data\\89.csv, 89 files out of an estimated total of 100\n",
      "Uploading batch-data\\9.csv\n",
      "Uploaded batch-data\\9.csv, 90 files out of an estimated total of 100\n",
      "Uploading batch-data\\90.csv\n",
      "Uploaded batch-data\\90.csv, 91 files out of an estimated total of 100\n",
      "Uploading batch-data\\91.csv\n",
      "Uploaded batch-data\\91.csv, 92 files out of an estimated total of 100\n",
      "Uploading batch-data\\92.csv\n",
      "Uploaded batch-data\\92.csv, 93 files out of an estimated total of 100\n",
      "Uploading batch-data\\93.csv\n",
      "Uploaded batch-data\\93.csv, 94 files out of an estimated total of 100\n",
      "Uploading batch-data\\94.csv\n",
      "Uploaded batch-data\\94.csv, 95 files out of an estimated total of 100\n",
      "Uploading batch-data\\95.csv\n",
      "Uploaded batch-data\\95.csv, 96 files out of an estimated total of 100\n",
      "Uploading batch-data\\96.csv\n",
      "Uploaded batch-data\\96.csv, 97 files out of an estimated total of 100\n",
      "Uploading batch-data\\97.csv\n",
      "Uploaded batch-data\\97.csv, 98 files out of an estimated total of 100\n",
      "Uploading batch-data\\98.csv\n",
      "Uploaded batch-data\\98.csv, 99 files out of an estimated total of 100\n",
      "Uploading batch-data\\99.csv\n",
      "Uploaded batch-data\\99.csv, 100 files out of an estimated total of 100\n",
      "Uploaded 100 files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore, Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set default data store\n",
    "ws.set_default_datastore('workspaceblobstore')\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)\n",
    "\n",
    "# Load the diabetes data\n",
    "diabetes = pd.read_csv('data/diabetes2.csv')\n",
    "# Get a 100-item sample of the feature columns (not the diabetic label)\n",
    "sample = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].sample(n=100).values\n",
    "\n",
    "# Create a folder\n",
    "batch_folder = './batch-data'\n",
    "os.makedirs(batch_folder, exist_ok=True)\n",
    "print(\"Folder created!\")\n",
    "\n",
    "# Save each sample as a separate file\n",
    "print(\"Saving files...\")\n",
    "for i in range(100):\n",
    "    fname = str(i+1) + '.csv'\n",
    "    sample[i].tofile(os.path.join(batch_folder, fname), sep=\",\")\n",
    "print(\"files saved!\")\n",
    "\n",
    "# Upload the files to the default datastore\n",
    "print(\"Uploading files to datastore...\")\n",
    "default_ds = ws.get_default_datastore()\n",
    "default_ds.upload(src_dir=\"batch-data\", target_path=\"batch-data\", overwrite=True, show_progress=True)\n",
    "\n",
    "# Register a dataset for the input data\n",
    "batch_data_set = Dataset.File.from_files(path=(default_ds, 'batch-data/'), validate=False)\n",
    "try:\n",
    "    batch_data_set = batch_data_set.register(workspace=ws, \n",
    "                                             name='batch-data',\n",
    "                                             description='batch data',\n",
    "                                             create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create compute\n",
    "\n",
    "We'll need a compute context for the pipeline, so we'll use the following code to specify an Azure Machine Learning compute cluster (it will be created if it doesn't already exist).\n",
    "\n",
    "> **Important**: Change *your-compute-cluster* to the name of your compute cluster in the code below before running it! Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"ComputerCluster\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    inference_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        inference_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        inference_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Compute instances and clusters are based on standard Azure virtual machine images. For this exercise, the *Standard_DS11_v2* image is recommended to achieve the optimal balance of cost and performance. If your subscription has a quota that does not include this image, choose an alternative image; but bear in mind that a larger image may incur higher cost and a smaller image may not be sufficient to complete the tasks. Alternatively, ask your Azure administrator to extend your quota.\n",
    "\n",
    "## Create a pipeline for batch inferencing\n",
    "\n",
    "Now we're ready to define the pipeline we'll use for batch inferencing. Our pipeline will need Python code to perform the batch inferencing, so let's create a folder where we can keep all the files used by the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'batch_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a Python script to do the actual work, and save it in the pipeline folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing batch_pipeline/batch_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/batch_diabetes.py\n",
    "import os\n",
    "import numpy as np\n",
    "from azureml.core import Model\n",
    "import joblib\n",
    "\n",
    "\n",
    "def init():\n",
    "    # Runs when the pipeline step is initialized\n",
    "    global model\n",
    "\n",
    "    # load the model\n",
    "    model_path = Model.get_model_path('diabetes_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "def run(mini_batch):\n",
    "    # This runs for each batch\n",
    "    resultList = []\n",
    "\n",
    "    # process each file in the batch\n",
    "    for f in mini_batch:\n",
    "        # Read the comma-delimited data into an array\n",
    "        data = np.genfromtxt(f, delimiter=',')\n",
    "        # Reshape into a 2-dimensional array for prediction (model expects multiple items)\n",
    "        prediction = model.predict(data.reshape(1, -1))\n",
    "        # Append prediction to results\n",
    "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline will need an environment in which to run, so we'll create a Conda specification that includes the packages that the code uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing batch_pipeline/batch_environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/batch_environment.yml\n",
    "name: batch_environment\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll define a run context that includes the Conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "# Create an Environment for the experiment\n",
    "batch_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/batch_environment.yml\")\n",
    "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "print('Configuration ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're going to use a pipeline to run the batch prediction script, generate predictions from the input data, and save the results as a text file in the output folder. To do this, you can use a **ParallelRunStep**, which enables the batch data to be processed in parallel and the results collated in a single output file named *parallel_run_step.txt*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "\n",
    "output_dir = OutputFileDatasetConfig(name='inferences')\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory=experiment_folder,\n",
    "    entry_script=\"batch_diabetes.py\",\n",
    "    mini_batch_size=\"5\",\n",
    "    error_threshold=10,\n",
    "    output_action=\"append_row\",\n",
    "    environment=batch_env,\n",
    "    compute_target=inference_cluster,\n",
    "    node_count=1)\n",
    "\n",
    "parallelrun_step = ParallelRunStep(\n",
    "    name='batch-score-diabetes',\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[batch_data_set.as_named_input('diabetes_batch')],\n",
    "    output=output_dir,\n",
    "    arguments=[],\n",
    "    allow_reuse=True\n",
    ")\n",
    "\n",
    "print('Steps defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to put the step into a pipeline, and run it.\n",
    "\n",
    "> **Note**: This may take some time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step batch-score-diabetes [9ede5c08][6ff81a5d-40e4-415c-a575-d32fcf47f389], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun dcdf5614-1f6e-4813-9715-f1dd51d77ed7\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/dcdf5614-1f6e-4813-9715-f1dd51d77ed7?wsid=/subscriptions/efaef50b-3a01-4bf1-ad06-b63c101ab300/resourcegroups/resource-group-1/workspaces/myworkspace&tid=cb956b3e-0e1a-485c-a395-a000041d2695\n",
      "PipelineRunId: dcdf5614-1f6e-4813-9715-f1dd51d77ed7\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/dcdf5614-1f6e-4813-9715-f1dd51d77ed7?wsid=/subscriptions/efaef50b-3a01-4bf1-ad06-b63c101ab300/resourcegroups/resource-group-1/workspaces/myworkspace&tid=cb956b3e-0e1a-485c-a395-a000041d2695\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 824ac1cc-588e-41cf-92a7-2a8da5460e83\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/824ac1cc-588e-41cf-92a7-2a8da5460e83?wsid=/subscriptions/efaef50b-3a01-4bf1-ad06-b63c101ab300/resourcegroups/resource-group-1/workspaces/myworkspace&tid=cb956b3e-0e1a-485c-a395-a000041d2695\n",
      "StepRun( batch-score-diabetes ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2022/12/30 01:27:21 Downloading source code...\n",
      "2022/12/30 01:27:22 Finished downloading source code\n",
      "2022/12/30 01:27:22 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2022/12/30 01:27:22 Successfully set up Docker network: acb_default_network\n",
      "2022/12/30 01:27:22 Setting up Docker configuration...\n",
      "2022/12/30 01:27:23 Successfully set up Docker configuration\n",
      "2022/12/30 01:27:23 Logging in to registry: 1635dc70ed624617b9f7f300373d982e.azurecr.io\n",
      "2022/12/30 01:27:23 Successfully logged into 1635dc70ed624617b9f7f300373d982e.azurecr.io\n",
      "2022/12/30 01:27:23 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2022/12/30 01:27:23 Scanning for dependencies...\n",
      "2022/12/30 01:27:24 Successfully scanned dependencies\n",
      "2022/12/30 01:27:24 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  71.68kB\n",
      "\n",
      "Step 1/21 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1@sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n",
      "mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1@sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b: Pulling from azureml/openmpi4.1.0-ubuntu20.04\n",
      "Digest: sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1@sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n",
      " ---> b6fd6a8d28e9\n",
      "Step 2/21 : USER root\n",
      " ---> Running in 8641a5f4fdfb\n",
      "Removing intermediate container 8641a5f4fdfb\n",
      " ---> 141948e984bd\n",
      "Step 3/21 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in aa86fa288214\n",
      "Removing intermediate container aa86fa288214\n",
      " ---> 105262444aa5\n",
      "Step 4/21 : WORKDIR /\n",
      " ---> Running in daec1421a525\n",
      "Removing intermediate container daec1421a525\n",
      " ---> f1a4f3e43f4d\n",
      "Step 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> bcc19c7e032a\n",
      "Step 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in a8d7cc867fb2\n",
      "Removing intermediate container a8d7cc867fb2\n",
      " ---> 5a4c0b4b042c\n",
      "Step 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> 4fe6187f8797\n",
      "Step 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 5033449e69b5\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "libgfortran4-7.5.0   | 995 KB    |            |   0% \n",
      "libgfortran4-7.5.0   | 995 KB    | ########## | 100% \n",
      "libgfortran4-7.5.0   | 995 KB    | ########## | 100% \n",
      "\n",
      "xz-5.2.8             | 429 KB    |            |   0% \n",
      "xz-5.2.8             | 429 KB    | ########## | 100% \n",
      "\n",
      "scikit-learn-0.24.2  | 5.2 MB    |            |   0% \n",
      "scikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \n",
      "scikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \n",
      "\n",
      "blas-1.0             | 6 KB      |            |   0% \n",
      "blas-1.0             | 6 KB      | ########## | 100% \n",
      "\n",
      "mkl-service-2.3.0    | 52 KB     |            |   0% \n",
      "mkl-service-2.3.0    | 52 KB     | ########## | 100% \n",
      "\n",
      "joblib-1.0.1         | 208 KB    |            |   0% \n",
      "joblib-1.0.1         | 208 KB    | ########## | 100% \n",
      "\n",
      "ncurses-6.0          | 781 KB    |            |   0% \n",
      "ncurses-6.0          | 781 KB    | ########## | 100% \n",
      "ncurses-6.0          | 781 KB    | ########## | 100% \n",
      "\n",
      "libgcc-ng-11.2.0     | 5.3 MB    |            |   0% \n",
      "libgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \n",
      "libgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \n",
      "\n",
      "libgomp-11.2.0       | 474 KB    |            |   0% \n",
      "libgomp-11.2.0       | 474 KB    | ########## | 100% \n",
      "\n",
      "_libgcc_mutex-0.1    | 3 KB      |            |   0% \n",
      "_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n",
      "\n",
      "pip-21.2.2           | 1.8 MB    |            |   0% \n",
      "pip-21.2.2           | 1.8 MB    | ########## | 100% \n",
      "pip-21.2.2           | 1.8 MB    | ########## | 100% \n",
      "\n",
      "libffi-3.2.1         | 48 KB     |            |   0% \n",
      "libffi-3.2.1         | 48 KB     | ########## | 100% \n",
      "\n",
      "numpy-1.19.2         | 22 KB     |            |   0% \n",
      "numpy-1.19.2         | 22 KB     | ########## | 100% \n",
      "\n",
      "readline-7.0         | 848 KB    |            |   0% \n",
      "readline-7.0         | 848 KB    | ########## | 100% \n",
      "\n",
      "certifi-2021.5.30    | 139 KB    |            |   0% \n",
      "certifi-2021.5.30    | 139 KB    | ########## | 100% \n",
      "\n",
      "mkl_fft-1.3.0        | 170 KB    |            |   0% \n",
      "mkl_fft-1.3.0        | 170 KB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2022 | 124 KB    |            |   0% \n",
      "ca-certificates-2022 | 124 KB    | ########## | 100% \n",
      "\n",
      "scipy-1.5.2          | 14.4 MB   |            |   0% \n",
      "scipy-1.5.2          | 14.4 MB   | ########## | 100% \n",
      "scipy-1.5.2          | 14.4 MB   | ########## | 100% \n",
      "\n",
      "openssl-1.0.2u       | 2.2 MB    |            |   0% \n",
      "openssl-1.0.2u       | 2.2 MB    | ########## | 100% \n",
      "\n",
      "zlib-1.2.13          | 103 KB    |            |   0% \n",
      "zlib-1.2.13          | 103 KB    | ########## | 100% \n",
      "\n",
      "sqlite-3.23.1        | 808 KB    |            |   0% \n",
      "sqlite-3.23.1        | 808 KB    | ########## | 100% \n",
      "\n",
      "intel-openmp-2022.1. | 4.5 MB    |            |   0% \n",
      "intel-openmp-2022.1. | 4.5 MB    | ########## | 100% \n",
      "intel-openmp-2022.1. | 4.5 MB    | ########## | 100% \n",
      "\n",
      "threadpoolctl-2.2.0  | 16 KB     |            |   0% \n",
      "threadpoolctl-2.2.0  | 16 KB     | ########## | 100% \n",
      "\n",
      "mkl_random-1.1.1     | 327 KB    |            |   0% \n",
      "mkl_random-1.1.1     | 327 KB    | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-11.2.0  | 4.7 MB    |            |   0% \n",
      "libstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \n",
      "libstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \n",
      "\n",
      "libgfortran-ng-7.5.0 | 22 KB     |            |   0% \n",
      "libgfortran-ng-7.5.0 | 22 KB     | ########## | 100% \n",
      "\n",
      "numpy-base-1.19.2    | 4.1 MB    |            |   0% \n",
      "numpy-base-1.19.2    | 4.1 MB    | ########## | 100% \n",
      "numpy-base-1.19.2    | 4.1 MB    | ########## | 100% \n",
      "\n",
      "six-1.16.0           | 18 KB     |            |   0% \n",
      "six-1.16.0           | 18 KB     | ########## | 100% \n",
      "\n",
      "tk-8.6.12            | 3.0 MB    |            |   0% \n",
      "tk-8.6.12            | 3.0 MB    | ########## | 100% \n",
      "\n",
      "python-3.6.2         | 23.6 MB   |            |   0% \n",
      "python-3.6.2         | 23.6 MB   | #######8   |  78% \n",
      "python-3.6.2         | 23.6 MB   | ########## | 100% \n",
      "\n",
      "libedit-3.1          | 151 KB    |            |   0% \n",
      "libedit-3.1          | 151 KB    | ########## | 100% \n",
      "\n",
      "setuptools-58.0.4    | 788 KB    |            |   0% \n",
      "setuptools-58.0.4    | 788 KB    | ########## | 100% \n",
      "\n",
      "_openmp_mutex-5.1    | 21 KB     |            |   0% \n",
      "_openmp_mutex-5.1    | 21 KB     | ########## | 100% \n",
      "\n",
      "mkl-2020.2           | 138.3 MB  |            |   0% \n",
      "mkl-2020.2           | 138.3 MB  | #3         |  14% \n",
      "mkl-2020.2           | 138.3 MB  | ###1       |  32% \n",
      "mkl-2020.2           | 138.3 MB  | ####9      |  50% \n",
      "mkl-2020.2           | 138.3 MB  | ######7    |  68% \n",
      "mkl-2020.2           | 138.3 MB  | ########4  |  85% \n",
      "mkl-2020.2           | 138.3 MB  | ########## | 100% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "wheel-0.37.1         | 33 KB     |            |   0% \n",
      "wheel-0.37.1         | 33 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... \n",
      "\n",
      "    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\n",
      "    More details are available here: https://intel.github.io/scikit-learn-intelex\n",
      "\n",
      "    For example:\n",
      "\n",
      "        $ conda install scikit-learn-intelex\n",
      "        $ python -m sklearnex my_application.py\n",
      "\n",
      "    \n",
      "\n",
      "done\n",
      "Installing pip dependencies: ...working... \n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.h9e4z1zw.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults\n",
      "  Downloading azureml_defaults-1.48.0-py3-none-any.whl (2.0 kB)\n",
      "Collecting azureml-inference-server-http~=0.7.2\n",
      "  Downloading azureml_inference_server_http-0.7.7-py3-none-any.whl (56 kB)\n",
      "Collecting azureml-defaults\n",
      "  Downloading azureml_defaults-1.47.0-py3-none-any.whl (2.0 kB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting azureml-core~=1.47.0\n",
      "  Downloading azureml_core-1.47.0-py3-none-any.whl (3.1 MB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.47.0\n",
      "  Downloading azureml_dataset_runtime-1.47.0-py3-none-any.whl (2.2 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting SecretStorage<4.0.0\n",
      "  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "Collecting ndg-httpsclient<=0.5.1\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting pathspec<1.0.0\n",
      "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting jsonpickle<3.0.0\n",
      "  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<41\n",
      "  Downloading cryptography-38.0.4-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "Collecting azure-mgmt-containerregistry<11,>=8.2.0\n",
      "  Downloading azure_mgmt_containerregistry-10.0.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting azure-common<2.0.0,>=1.1.12\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting msrest<=0.7.1,>=0.5.1\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "Collecting contextlib2<22.0.0\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.7.3\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting paramiko<3.0.0,>=2.0.8\n",
      "  Downloading paramiko-2.12.0-py2.py3-none-any.whl (213 kB)\n",
      "Collecting adal<=1.2.7,>=1.2.0\n",
      "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Collecting msrestazure<=0.6.4,>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting jmespath<2.0.0\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting azure-mgmt-resource<22.0.0,>=15.0.0\n",
      "  Downloading azure_mgmt_resource-21.1.0-py3-none-any.whl (1.8 MB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting urllib3<2.0.0,>=1.23\n",
      "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "Collecting PyJWT<3.0.0\n",
      "  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
      "Collecting humanfriendly<11.0,>=4.7\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting pkginfo\n",
      "  Downloading pkginfo-1.9.2-py3-none-any.whl (26 kB)\n",
      "Collecting azure-mgmt-keyvault<11.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-10.0.0-py3-none-any.whl (489 kB)\n",
      "Collecting requests[socks]<3.0.0,>=2.19.1\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting msal-extensions<=1.0.0,>=0.3.0\n",
      "  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting azure-mgmt-storage<21.0.0,>=16.0.0\n",
      "  Downloading azure_mgmt_storage-20.0.0-py3-none-any.whl (2.0 MB)\n",
      "Collecting azure-core<2.0.0\n",
      "  Downloading azure_core-1.24.2-py3-none-any.whl (178 kB)\n",
      "Collecting argcomplete<3\n",
      "  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Collecting msal<2.0.0,>=1.15.0\n",
      "  Downloading msal-1.20.0-py2.py3-none-any.whl (90 kB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2022.7-py2.py3-none-any.whl (499 kB)\n",
      "Collecting docker<7.0.0\n",
      "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
      "Collecting pyopenssl<23.0.0\n",
      "  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)\n",
      "Collecting packaging<22.0,>=20.0\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting azure-mgmt-authorization<3,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-2.0.0-py2.py3-none-any.whl (465 kB)\n",
      "Collecting knack~=0.10.0\n",
      "  Downloading knack-0.10.1-py3-none-any.whl (61 kB)\n",
      "Collecting importlib-metadata<5,>=0.23\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from azure-core<2.0.0->azureml-core~=1.47.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h9e4z1zw.requirements.txt (line 1)) (1.16.0)\n",
      "Collecting typing-extensions>=4.0.1\n",
      "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.2.0\n",
      "  Downloading azure_mgmt_core-1.3.2-py3-none-any.whl (26 kB)\n",
      "Collecting pyarrow<=9.0.0,>=0.17.0\n",
      "  Downloading pyarrow-6.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n",
      "Requirement already satisfied: numpy!=1.19.3 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from azureml-dataset-runtime[fuse]~=1.47.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h9e4z1zw.requirements.txt (line 1)) (1.19.2)\n",
      "Collecting azureml-dataprep<4.6.0a,>=4.5.0a\n",
      "  Downloading azureml_dataprep-4.5.7-py3-none-any.whl (43.4 MB)\n",
      "Collecting fusepy<4.0.0,>=3.0.1\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting cloudpickle<3.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting azureml-dataprep-native<39.0.0,>=38.0.0\n",
      "  Downloading azureml_dataprep_native-38.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting azure-identity==1.7.0\n",
      "  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\n",
      "Collecting jsonschema\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting pyyaml<7.0.0,>=5.1.0\n",
      "  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\n",
      "Collecting dotnetcore2<4.0.0,>=3.0.0\n",
      "  Downloading dotnetcore2-3.1.23-py3-none-manylinux1_x86_64.whl (31.1 MB)\n",
      "Collecting azureml-dataprep-rslex~=2.11.0dev0\n",
      "  Downloading azureml_dataprep_rslex-2.11.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\n",
      "Collecting msal-extensions<=1.0.0,>=0.3.0\n",
      "  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting inference-schema~=1.4.0\n",
      "  Downloading inference_schema-1.4.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting opencensus-ext-azure~=1.1.0\n",
      "  Downloading opencensus_ext_azure-1.1.7-py2.py3-none-any.whl (42 kB)\n",
      "Collecting gunicorn==20.1.0\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting flask-cors~=3.0.1\n",
      "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from gunicorn==20.1.0->azureml-inference-server-http~=0.7.2->azureml-defaults->-r /azureml-environment-setup/condaenv.h9e4z1zw.requirements.txt (line 1)) (58.0.4)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.15.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (402 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting Flask>=0.9\n",
      "  Downloading Flask-2.0.3-py3-none-any.whl (95 kB)\n",
      "Collecting Jinja2>=3.0\n",
      "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "Collecting click>=7.1.2\n",
      "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting wrapt<=1.12.1,>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
      "Collecting pygments\n",
      "  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting portalocker<3,>=1.0\n",
      "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.47.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h9e4z1zw.requirements.txt (line 1)) (2021.5.30)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting opencensus<1.0.0,>=0.11.0\n",
      "  Downloading opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\n",
      "Collecting psutil>=5.6.3\n",
      "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0\n",
      "  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\n",
      "Collecting opencensus-context>=0.1.3\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Collecting google-auth<3.0dev,>=1.25.0\n",
      "  Downloading google_auth-2.15.0-py2.py3-none-any.whl (177 kB)\n",
      "Collecting protobuf<5.0.0dev,>=3.15.0\n",
      "  Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.56.3-py2.py3-none-any.whl (211 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting contextvars\n",
      "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting immutables>=0.9\n",
      "  Downloading immutables-0.19-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (116 kB)\n",
      "Collecting attrs>=17.4.0\n",
      "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.18.0-cp36-cp36m-manylinux1_x86_64.whl (117 kB)\n",
      "Building wheels for collected packages: json-logging-py, fusepy, wrapt, contextvars\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=83edba0af97f9a6af7dd3da14f46f68156c3ef83d50bdb50832204f7abedf523\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=fb9c266e99ff0017a1f0b6f1445cbde8ab7bd73ed138306e61e4c1024670b4c0\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=76172 sha256=9ba93b21c49f2b562a53e32df74243cec5fb4f062f978606c5bc30359b6d0adf\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "  Building wheel for contextvars (setup.py): started\n",
      "  Building wheel for contextvars (setup.py): finished with status 'done'\n",
      "  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7681 sha256=9aa1b763d2a3e1201c199a6e5ec28e92663f917d9fc5dbcfe9bf2ffbf4773874\n",
      "  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\n",
      "Successfully built json-logging-py fusepy wrapt contextvars\n",
      "Installing collected packages: pycparser, cffi, urllib3, PyJWT, idna, cryptography, charset-normalizer, typing-extensions, requests, pyasn1, zipp, rsa, pyasn1-modules, protobuf, portalocker, oauthlib, msal, immutables, cachetools, requests-oauthlib, python-dateutil, pyrsistent, msal-extensions, MarkupSafe, isodate, importlib-metadata, googleapis-common-protos, google-auth, distro, dataclasses, contextvars, azure-core, attrs, Werkzeug, pyyaml, opencensus-context, msrest, jsonschema, Jinja2, itsdangerous, google-api-core, dotnetcore2, cloudpickle, click, azureml-dataprep-rslex, azureml-dataprep-native, azure-identity, adal, wrapt, websocket-client, tabulate, pytz, PySocks, pyparsing, pyopenssl, pynacl, pygments, pyarrow, psutil, opencensus, msrestazure, jmespath, jeepney, Flask, bcrypt, backports.weakref, azureml-dataprep, azure-mgmt-core, azure-common, argcomplete, SecretStorage, pkginfo, pathspec, paramiko, packaging, opencensus-ext-azure, ndg-httpsclient, knack, jsonpickle, inference-schema, humanfriendly, gunicorn, fusepy, flask-cors, docker, contextlib2, backports.tempfile, azureml-dataset-runtime, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, json-logging-py, configparser, azureml-inference-server-http, azureml-core, azureml-defaults\n",
      "Successfully installed Flask-2.0.3 Jinja2-3.0.3 MarkupSafe-2.0.1 PyJWT-2.4.0 PySocks-1.7.1 SecretStorage-3.3.3 Werkzeug-2.0.3 adal-1.2.7 argcomplete-2.0.0 attrs-22.2.0 azure-common-1.1.28 azure-core-1.24.2 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-2.0.0 azure-mgmt-containerregistry-10.0.0 azure-mgmt-core-1.3.2 azure-mgmt-keyvault-10.0.0 azure-mgmt-resource-21.1.0 azure-mgmt-storage-20.0.0 azureml-core-1.47.0 azureml-dataprep-4.5.7 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.11.4 azureml-dataset-runtime-1.47.0 azureml-defaults-1.47.0 azureml-inference-server-http-0.7.7 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.0.1 cachetools-4.2.4 cffi-1.15.1 charset-normalizer-2.0.12 click-8.0.4 cloudpickle-2.2.0 configparser-3.7.4 contextlib2-21.6.0 contextvars-2.4 cryptography-38.0.4 dataclasses-0.8 distro-1.8.0 docker-5.0.3 dotnetcore2-3.1.23 flask-cors-3.0.10 fusepy-3.0.1 google-api-core-2.8.2 google-auth-2.15.0 googleapis-common-protos-1.56.3 gunicorn-20.1.0 humanfriendly-10.0 idna-3.4 immutables-0.19 importlib-metadata-4.8.3 inference-schema-1.4.2.1 isodate-0.6.1 itsdangerous-2.0.1 jeepney-0.7.1 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.2.0 jsonschema-3.2.0 knack-0.10.1 msal-1.20.0 msal-extensions-0.3.1 msrest-0.7.1 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.2.2 opencensus-0.11.0 opencensus-context-0.1.3 opencensus-ext-azure-1.1.7 packaging-21.3 paramiko-2.12.0 pathspec-0.9.0 pkginfo-1.9.2 portalocker-2.6.0 protobuf-3.19.6 psutil-5.9.4 pyarrow-6.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pygments-2.13.0 pynacl-1.5.0 pyopenssl-22.1.0 pyparsing-3.0.7 pyrsistent-0.18.0 python-dateutil-2.8.2 pytz-2022.7 pyyaml-6.0 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.9 tabulate-0.8.10 typing-extensions-4.1.1 urllib3-1.26.13 websocket-client-1.3.1 wrapt-1.12.1 zipp-3.6.0\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.12.0\n",
      "  latest version: 22.11.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: /root/.conda/pkgs does not exist\n",
      "Removing intermediate container 5033449e69b5\n",
      " ---> f52ea72fb714\n",
      "Step 9/21 : ENV PATH /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/bin:$PATH\n",
      " ---> Running in be6796156e18\n",
      "Removing intermediate container be6796156e18\n",
      " ---> 0c9eb4096443\n",
      "Step 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      " ---> 455f0ed5ab92\n",
      "Step 11/21 : RUN echo \"Copying environment context\"\n",
      " ---> Running in ff580220441e\n",
      "Copying environment context\n",
      "Removing intermediate container ff580220441e\n",
      " ---> 82ec50d2dbb8\n",
      "Step 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      " ---> 7c5c571b52ac\n",
      "Step 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n",
      " ---> Running in 1567a77ad617\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Sending request with materialized conda environment details\n",
      "Successfully sent materialized environment details\n",
      "Removing intermediate container 1567a77ad617\n",
      " ---> c93da2c17be0\n",
      "Step 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n",
      " ---> Running in 0347fafa0d3e\n",
      "Removing intermediate container 0347fafa0d3e\n",
      " ---> cfdc3f450fa0\n",
      "Step 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in b8ff322de18b\n",
      "Removing intermediate container b8ff322de18b\n",
      " ---> 9e02ef7feb28\n",
      "Step 16/21 : ENV CONDA_DEFAULT_ENV=azureml_e220b045f6c3c3008b1a386af067185d CONDA_PREFIX=/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n",
      " ---> Running in 72d74a3afa0e\n",
      "Removing intermediate container 72d74a3afa0e\n",
      " ---> 6d6cfe5a04da\n",
      "Step 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 8b221f4bcb45\n",
      "Step 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 8ff1facdb0cb\n",
      "Removing intermediate container 8ff1facdb0cb\n",
      " ---> 2b565d676a19\n",
      "Step 19/21 : RUN rm -rf azureml-environment-setup\n",
      " ---> Running in 66b7a7a28399\n",
      "Removing intermediate container 66b7a7a28399\n",
      " ---> 43a381b76149\n",
      "Step 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 12e611f5e2c5\n",
      "Removing intermediate container 12e611f5e2c5\n",
      " ---> 0ff96f599634\n",
      "Step 21/21 : CMD [\"bash\"]\n",
      " ---> Running in 324f7f82cdcb\n",
      "Removing intermediate container 324f7f82cdcb\n",
      " ---> 36342e92530e\n",
      "Successfully built 36342e92530e\n",
      "Successfully tagged 1635dc70ed624617b9f7f300373d982e.azurecr.io/azureml/azureml_7c19e7da749e0437ab8fe27bfd12dde1:latest\n",
      "Successfully tagged 1635dc70ed624617b9f7f300373d982e.azurecr.io/azureml/azureml_7c19e7da749e0437ab8fe27bfd12dde1:1\n",
      "2022/12/30 01:29:08 Successfully executed container: acb_step_0\n",
      "2022/12/30 01:29:08 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2022/12/30 01:29:08 Pushing image: 1635dc70ed624617b9f7f300373d982e.azurecr.io/azureml/azureml_7c19e7da749e0437ab8fe27bfd12dde1:1, attempt 1\n",
      "The push refers to repository [1635dc70ed624617b9f7f300373d982e.azurecr.io/azureml/azureml_7c19e7da749e0437ab8fe27bfd12dde1]\n",
      "1e3f4570b723: Preparing\n",
      "4a34c71057a4: Preparing\n",
      "d1e201e77bb3: Preparing\n",
      "1d7911b465ae: Preparing\n",
      "25e936cdb398: Preparing\n",
      "bb931144fdf1: Preparing\n",
      "f31b492d80ff: Preparing\n",
      "00ea32a593bf: Preparing\n",
      "a434b00d637b: Preparing\n",
      "810f01ca3847: Preparing\n",
      "2bcdf82aed44: Preparing\n",
      "b21e039321ee: Preparing\n",
      "445a2d2462f0: Preparing\n",
      "6e539e6b11c3: Preparing\n",
      "b67f8b8feccd: Preparing\n",
      "7e60813e02c4: Preparing\n",
      "0d66ccba1288: Preparing\n",
      "20b46ade1e43: Preparing\n",
      "21d33b1352c9: Preparing\n",
      "af7ed92504ae: Preparing\n",
      "b21e039321ee: Waiting\n",
      "445a2d2462f0: Waiting\n",
      "6e539e6b11c3: Waiting\n",
      "b67f8b8feccd: Waiting\n",
      "7e60813e02c4: Waiting\n",
      "0d66ccba1288: Waiting\n",
      "20b46ade1e43: Waiting\n",
      "21d33b1352c9: Waiting\n",
      "af7ed92504ae: Waiting\n",
      "bb931144fdf1: Waiting\n",
      "f31b492d80ff: Waiting\n",
      "00ea32a593bf: Waiting\n",
      "a434b00d637b: Waiting\n",
      "810f01ca3847: Waiting\n",
      "2bcdf82aed44: Waiting\n",
      "4a34c71057a4: Pushed\n",
      "25e936cdb398: Pushed\n",
      "1d7911b465ae: Pushed\n",
      "1e3f4570b723: Pushed\n",
      "f31b492d80ff: Pushed\n",
      "a434b00d637b: Pushed\n",
      "d1e201e77bb3: Pushed\n",
      "810f01ca3847: Pushed\n",
      "00ea32a593bf: Pushed\n",
      "b21e039321ee: Pushed\n",
      "2bcdf82aed44: Pushed\n",
      "7e60813e02c4: Pushed\n",
      "445a2d2462f0: Pushed\n",
      "6e539e6b11c3: Pushed\n",
      "0d66ccba1288: Pushed\n",
      "20b46ade1e43: Pushed\n",
      "af7ed92504ae: Pushed\n",
      "b67f8b8feccd: Pushed\n",
      "21d33b1352c9: Pushed\n",
      "bb931144fdf1: Pushed\n",
      "1: digest: sha256:2ece16f28bffb9c14509a6aa06ff6256fa134c49cab671910ee7494476cdd951 size: 4514\n",
      "2022/12/30 01:30:47 Successfully pushed image: 1635dc70ed624617b9f7f300373d982e.azurecr.io/azureml/azureml_7c19e7da749e0437ab8fe27bfd12dde1:1\n",
      "2022/12/30 01:30:47 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2022/12/30 01:30:47 Pushing image: 1635dc70ed624617b9f7f300373d982e.azurecr.io/azureml/azureml_7c19e7da749e0437ab8fe27bfd12dde1:latest, attempt 1\n",
      "The push refers to repository [1635dc70ed624617b9f7f300373d982e.azurecr.io/azureml/azureml_7c19e7da749e0437ab8fe27bfd12dde1]\n",
      "1e3f4570b723: Preparing\n",
      "4a34c71057a4: Preparing\n",
      "d1e201e77bb3: Preparing\n",
      "1d7911b465ae: Preparing\n",
      "25e936cdb398: Preparing\n",
      "bb931144fdf1: Preparing\n",
      "f31b492d80ff: Preparing\n",
      "00ea32a593bf: Preparing\n",
      "a434b00d637b: Preparing\n",
      "810f01ca3847: Preparing\n",
      "2bcdf82aed44: Preparing\n",
      "b21e039321ee: Preparing\n",
      "445a2d2462f0: Preparing\n",
      "6e539e6b11c3: Preparing\n",
      "b67f8b8feccd: Preparing\n",
      "7e60813e02c4: Preparing\n",
      "0d66ccba1288: Preparing\n",
      "20b46ade1e43: Preparing\n",
      "21d33b1352c9: Preparing\n",
      "af7ed92504ae: Preparing\n",
      "bb931144fdf1: Waiting\n",
      "f31b492d80ff: Waiting\n",
      "00ea32a593bf: Waiting\n",
      "a434b00d637b: Waiting\n",
      "810f01ca3847: Waiting\n",
      "2bcdf82aed44: Waiting\n",
      "b21e039321ee: Waiting\n",
      "445a2d2462f0: Waiting\n",
      "6e539e6b11c3: Waiting\n",
      "b67f8b8feccd: Waiting\n",
      "7e60813e02c4: Waiting\n",
      "0d66ccba1288: Waiting\n",
      "20b46ade1e43: Waiting\n",
      "21d33b1352c9: Waiting\n",
      "af7ed92504ae: Waiting\n",
      "1e3f4570b723: Layer already exists\n",
      "1d7911b465ae: Layer already exists\n",
      "d1e201e77bb3: Layer already exists\n",
      "25e936cdb398: Layer already exists\n",
      "4a34c71057a4: Layer already exists\n",
      "bb931144fdf1: Layer already exists\n",
      "00ea32a593bf: Layer already exists\n",
      "f31b492d80ff: Layer already exists\n",
      "a434b00d637b: Layer already exists\n",
      "810f01ca3847: Layer already exists\n",
      "445a2d2462f0: Layer already exists\n",
      "2bcdf82aed44: Layer already exists\n",
      "b21e039321ee: Layer already exists\n",
      "b67f8b8feccd: Layer already exists\n",
      "6e539e6b11c3: Layer already exists\n",
      "7e60813e02c4: Layer already exists\n",
      "af7ed92504ae: Layer already exists\n",
      "21d33b1352c9: Layer already exists\n",
      "20b46ade1e43: Layer already exists\n",
      "0d66ccba1288: Layer already exists\n",
      "latest: digest: sha256:2ece16f28bffb9c14509a6aa06ff6256fa134c49cab671910ee7494476cdd951 size: 4514\n",
      "2022/12/30 01:30:54 Successfully pushed image: 1635dc70ed624617b9f7f300373d982e.azurecr.io/azureml/azureml_7c19e7da749e0437ab8fe27bfd12dde1:latest\n",
      "2022/12/30 01:30:54 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 104.253964)\n",
      "2022/12/30 01:30:54 Populating digests for step ID: acb_step_0...\n",
      "2022/12/30 01:30:55 Successfully populated digests for step ID: acb_step_0\n",
      "2022/12/30 01:30:55 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 99.528799)\n",
      "2022/12/30 01:30:55 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 6.469440)\n",
      "2022/12/30 01:30:55 The following dependencies were found:\n",
      "2022/12/30 01:30:55 \n",
      "- image:\n",
      "    registry: 1635dc70ed624617b9f7f300373d982e.azurecr.io\n",
      "    repository: azureml/azureml_7c19e7da749e0437ab8fe27bfd12dde1\n",
      "    tag: latest\n",
      "    digest: sha256:2ece16f28bffb9c14509a6aa06ff6256fa134c49cab671910ee7494476cdd951\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi4.1.0-ubuntu20.04\n",
      "    tag: 20221101.v1\n",
      "    digest: sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n",
      "  git: {}\n",
      "- image:\n",
      "    registry: 1635dc70ed624617b9f7f300373d982e.azurecr.io\n",
      "    repository: azureml/azureml_7c19e7da749e0437ab8fe27bfd12dde1\n",
      "    tag: \"1\"\n",
      "    digest: sha256:2ece16f28bffb9c14509a6aa06ff6256fa134c49cab671910ee7494476cdd951\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi4.1.0-ubuntu20.04\n",
      "    tag: 20221101.v1\n",
      "    digest: sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n",
      "  git: {}\n",
      "\n",
      "Run ID: ch5 was successful after 3m34s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StepRun(batch-score-diabetes) Execution Summary\n",
      "================================================\n",
      "StepRun( batch-score-diabetes ) Status: Failed\n",
      "\n",
      "Warnings:\n",
      "AzureMLCompute job failed.\n",
      "ExecutionFailed: [REDACTED]\n",
      "\t: 1\n",
      "Execution failed. User process '/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/bin/python' exited with status code 1. Please check log file 'user_logs/std_log_0.txt' for error details. Error: Traceback (most recent call last):\n",
      "  File \"driver/amlbi\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Execution failed. User process '/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/bin/python' exited with status code 1. Please check log file 'user_logs/std_log_0.txt' for error details. Error: Traceback (most recent call last):\\n  File \\\"driver/amlbi_main.py\\\", line 184, in <module>\\n    main()\\n  File \\\"driver/amlbi_main.py\\\", line 126, in main\\n    boot(driver_dir)\\n  File \\\"driver/amlbi_main.py\\\", line 58, in boot\\n    booter.start()\\n  File \\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot.py\\\", line 382, in start\\n    self.start_sys_main()\\n  File \\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot.py\\\", line 268, in start_sys_main\\n    self.run_sys_main(cmd)\\n  File \\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot_node.py\\\", line 124, in run_sys_main\\n    self.check_run_result(proc=proc, stdout=stdout or \\\"\\\", stderr=stderr or \\\"\\\")\\n  File \\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot.py\\\", line 217, in check_run_result\\n    BootResult().check_result(stdout)\\n  File \\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot_result.py\\\", line 36, in check_result\\n    raise Exception(message) from cause\\nException: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\\n\\n\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\",\n    \"componentName\": \"CommonRuntime\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Execution failed. User process '/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/bin/python' exited with status code 1. Please check log file 'user_logs/std_log_0.txt' for error details. Error: Traceback (most recent call last):\\\\n  File \\\\\\\"driver/amlbi_main.py\\\\\\\", line 184, in <module>\\\\n    main()\\\\n  File \\\\\\\"driver/amlbi_main.py\\\\\\\", line 126, in main\\\\n    boot(driver_dir)\\\\n  File \\\\\\\"driver/amlbi_main.py\\\\\\\", line 58, in boot\\\\n    booter.start()\\\\n  File \\\\\\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot.py\\\\\\\", line 382, in start\\\\n    self.start_sys_main()\\\\n  File \\\\\\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot.py\\\\\\\", line 268, in start_sys_main\\\\n    self.run_sys_main(cmd)\\\\n  File \\\\\\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot_node.py\\\\\\\", line 124, in run_sys_main\\\\n    self.check_run_result(proc=proc, stdout=stdout or \\\\\\\"\\\\\\\", stderr=stderr or \\\\\\\"\\\\\\\")\\\\n  File \\\\\\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot.py\\\\\\\", line 217, in check_run_result\\\\n    BootResult().check_result(stdout)\\\\n  File \\\\\\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot_result.py\\\\\\\", line 36, in check_result\\\\n    raise Exception(message) from cause\\\\nException: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\\\\n\\\\n\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\",\\n    \\\"componentName\\\": \\\"CommonRuntime\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(workspace\u001b[38;5;241m=\u001b[39mws, steps\u001b[38;5;241m=\u001b[39m[parallelrun_step])\n\u001b[0;32m      5\u001b[0m pipeline_run \u001b[38;5;241m=\u001b[39m Experiment(ws, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmslearn-diabetes-batch\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msubmit(pipeline)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mpipeline_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\az\\lib\\site-packages\\azureml\\pipeline\\core\\run.py:295\u001b[0m, in \u001b[0;36mPipelineRun.wait_for_completion\u001b[1;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 295\u001b[0m     \u001b[43mstep_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime_elapsed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;66;03m# If there are package conflicts in the user's environment, the run rehydration\u001b[39;00m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# will not work and we will receive a Run object instead of StepRun.\u001b[39;00m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;66;03m# Run.wait_for_completion() does not have a parameter timeout_seconds, which\u001b[39;00m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;66;03m# will generate a TypeError here.  As a workaround, call the method without\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;66;03m# this parameter.\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step_run, StepRun):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\az\\lib\\site-packages\\azureml\\pipeline\\core\\run.py:738\u001b[0m, in \u001b[0;36mStepRun.wait_for_completion\u001b[1;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_output:\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 738\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_run_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m    741\u001b[0m         error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output streaming for the run interrupted.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    742\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBut the run is still executing on the compute target. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    743\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetails for canceling the run can be found here: \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    744\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://aka.ms/aml-docs-cancel-run\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\az\\lib\\site-packages\\azureml\\pipeline\\core\\run.py:831\u001b[0m, in \u001b[0;36mStepRun._stream_run_output\u001b[1;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mand\u001b[39;00m raise_on_error:\n\u001b[1;32m--> 831\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ActivityFailedException(error_details\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_details)\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Execution failed. User process '/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/bin/python' exited with status code 1. Please check log file 'user_logs/std_log_0.txt' for error details. Error: Traceback (most recent call last):\\n  File \\\"driver/amlbi_main.py\\\", line 184, in <module>\\n    main()\\n  File \\\"driver/amlbi_main.py\\\", line 126, in main\\n    boot(driver_dir)\\n  File \\\"driver/amlbi_main.py\\\", line 58, in boot\\n    booter.start()\\n  File \\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot.py\\\", line 382, in start\\n    self.start_sys_main()\\n  File \\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot.py\\\", line 268, in start_sys_main\\n    self.run_sys_main(cmd)\\n  File \\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot_node.py\\\", line 124, in run_sys_main\\n    self.check_run_result(proc=proc, stdout=stdout or \\\"\\\", stderr=stderr or \\\"\\\")\\n  File \\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot.py\\\", line 217, in check_run_result\\n    BootResult().check_result(stdout)\\n  File \\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot_result.py\\\", line 36, in check_result\\n    raise Exception(message) from cause\\nException: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\\n\\n\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\",\n    \"componentName\": \"CommonRuntime\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Execution failed. User process '/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/bin/python' exited with status code 1. Please check log file 'user_logs/std_log_0.txt' for error details. Error: Traceback (most recent call last):\\\\n  File \\\\\\\"driver/amlbi_main.py\\\\\\\", line 184, in <module>\\\\n    main()\\\\n  File \\\\\\\"driver/amlbi_main.py\\\\\\\", line 126, in main\\\\n    boot(driver_dir)\\\\n  File \\\\\\\"driver/amlbi_main.py\\\\\\\", line 58, in boot\\\\n    booter.start()\\\\n  File \\\\\\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot.py\\\\\\\", line 382, in start\\\\n    self.start_sys_main()\\\\n  File \\\\\\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot.py\\\\\\\", line 268, in start_sys_main\\\\n    self.run_sys_main(cmd)\\\\n  File \\\\\\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot_node.py\\\\\\\", line 124, in run_sys_main\\\\n    self.check_run_result(proc=proc, stdout=stdout or \\\\\\\"\\\\\\\", stderr=stderr or \\\\\\\"\\\\\\\")\\\\n  File \\\\\\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot.py\\\\\\\", line 217, in check_run_result\\\\n    BootResult().check_result(stdout)\\\\n  File \\\\\\\"/mnt/azureml/cr/j/fa1419f5581d443ab87e89d69f8cbdc2/exe/wd/driver/azureml_user/parallel_run/boot_result.py\\\\\\\", line 36, in check_result\\\\n    raise Exception(message) from cause\\\\nException: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\\\\n\\\\n\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\",\\n    \\\"componentName\\\": \\\"CommonRuntime\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
    "pipeline_run = Experiment(ws, 'mslearn-diabetes-batch').submit(pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the pipeline has finished running, the resulting predictions will have been saved in the outputs of the experiment associated with the first (and only) step in the pipeline. You can retrieve it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Remove the local results folder if left over from a previous run\n",
    "shutil.rmtree('diabetes-results', ignore_errors=True)\n",
    "\n",
    "# Get the run for the first step and download its output\n",
    "prediction_run = next(pipeline_run.get_children())\n",
    "prediction_output = prediction_run.get_output_data('inferences')\n",
    "prediction_output.download(local_path='diabetes-results')\n",
    "\n",
    "# Traverse the folder hierarchy and find the results file\n",
    "for root, dirs, files in os.walk('diabetes-results'):\n",
    "    for file in files:\n",
    "        if file.endswith('parallel_run_step.txt'):\n",
    "            result_file = os.path.join(root,file)\n",
    "\n",
    "# cleanup output format\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "df.columns = [\"File\", \"Prediction\"]\n",
    "\n",
    "# Display the first 20 results\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the Pipeline and use its REST Interface\n",
    "\n",
    "Now that you have a working pipeline for batch inferencing, you can publish it and use a REST endpoint to run it from an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name='diabetes-batch-pipeline', description='Batch scoring of diabetes data', version='1.0')\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the published pipeline has an endpoint, which you can see in the Azure portal. You can also find it as a property of the published pipeline object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. To test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:\n",
    "\n",
    "> **Note**: A real application would require a service principal with which to be authenticated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print('Authentication header ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to call the REST interface. The pipeline runs asynchronously, so we'll get an identifier back, which we can use to track the pipeline experiment as it runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": \"mslearn-diabetes-batch\"})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have the run ID, we can use the **RunDetails** widget to view the experiment as it runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments['mslearn-diabetes-batch'], run_id)\n",
    "\n",
    "# Block until the run completes\n",
    "published_pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the pipeline run to complete, and then run the following cell to see the results.\n",
    "\n",
    "As before, the results are in the output of the first pipeline step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Remove the local results folder if left over from a previous run\n",
    "shutil.rmtree('diabetes-results', ignore_errors=True)\n",
    "\n",
    "# Get the run for the first step and download its output\n",
    "prediction_run = next(pipeline_run.get_children())\n",
    "prediction_output = prediction_run.get_output_data('inferences')\n",
    "prediction_output.download(local_path='diabetes-results')\n",
    "\n",
    "# Traverse the folder hierarchy and find the results file\n",
    "for root, dirs, files in os.walk('diabetes-results'):\n",
    "    for file in files:\n",
    "        if file.endswith('parallel_run_step.txt'):\n",
    "            result_file = os.path.join(root,file)\n",
    "\n",
    "# cleanup output format\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "df.columns = [\"File\", \"Prediction\"]\n",
    "\n",
    "# Display the first 20 results\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a pipeline that can be used to batch process daily patient data.\n",
    "\n",
    "**More Information**: For more details about using pipelines for batch inferencing, see the [How to Run Batch Predictions](https://docs.microsoft.com/azure/machine-learning/how-to-run-batch-predictions) in the Azure Machine Learning documentation."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
