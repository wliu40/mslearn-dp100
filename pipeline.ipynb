{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "207861c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### How to log \n",
    "### How to register a data\n",
    "### How to retrieve data from datastore / workspace (registered)\n",
    "### Check all experiments in a workspace\n",
    "### Check all runs in a experiment\n",
    "### Get a specific run by its tag/property\n",
    "### Tag runs, add properties\n",
    "\n",
    "### How to register a model\n",
    "### Review all registered models\n",
    "### Retrieve a model by its tag\n",
    "\n",
    "\n",
    "### How to create a new environment\n",
    "### How to register a enviroment\n",
    "\n",
    "\n",
    "### How to create a new compute cluster\n",
    "### How to create a run config for pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4fb5a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Run, ScriptRunConfig\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.widgets import RunDetails\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20516692",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = 'playground'\n",
    "os.makedirs(script_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc7c0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting playground/data_prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_dir/data_prep.py\n",
    "import os\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "from sklearn.processing import MinMaxScaler\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--input_data', type=str, dest='raw_dataset', help='Raw dataset')\n",
    "parser.add_argument('--preped_data', type=str, dest='preped_dataset', help='Prepared dataset')\n",
    "args = parser.parse_args()\n",
    "\n",
    "saved_dir = args.preped_data\n",
    "run = Run.get_context()\n",
    "\n",
    "df = run.input_datasets['raw_dataset'].to_pandas_dataframe()\n",
    "\n",
    "num_features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure',\n",
    "                'TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
    "scaler = MinMaxScaler()\n",
    "df[num_features] = scaler.fit(df[num_features])\n",
    "\n",
    "print('saving data to preped_data')\n",
    "os.makedirs(saved_dir, exist_ok=True)\n",
    "df.to_csv(os.path.join(saved_dir, 'preped_data.csv'), index=False)\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b42be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting playground/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_dir/train.py\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import numpy as np\n",
    "from azureml.core import Run, Model\n",
    "import joblib\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--input_data', type=str, dest='input_data', help='Input dataset for model')\n",
    "args = parser.parse_args()\n",
    "\n",
    "run = Run.get_context()\n",
    "df = run.input_datsets['input_data'].to_pandas_dataframe()\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(df, test_size=.3, random_state=0)\n",
    "\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ACC\n",
    "acc = np.average(y_pred==y_test)\n",
    "run.log(name='acc', value=acc)\n",
    "\n",
    "# AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test, y_scores[:, 1])\n",
    "run.log(name='auc', value=auc)\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_score[:,1])\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.plot([0,1], [0,1], 'k--')\n",
    "ax.plot(fpr, tpr)\n",
    "ax.title('ROC curve')\n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "run.log_image(name='roc_curve', plot=fig)\n",
    "\n",
    "print('Saving model')\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "model_file_path = os.path.join('models', 'diabetes_model.pkl')\n",
    "joblib.dump(model, model_file_path)\n",
    "\n",
    "Model.register(workspace=ws,\n",
    "              model_path=model_file,\n",
    "              tags={\"training context\": \"pipeline\"},\n",
    "              properties={'AUC': auc, \"ACC\": acc},\n",
    "              model_Path=model_file_path)\n",
    "run.complete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11bcb397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "datastore = ws.get_default_datastore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a3fd63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_dataset2\n",
      "batch-data\n",
      "diabetes file dataset\n",
      "diabetes dataset\n",
      "loan_data\n"
     ]
    }
   ],
   "source": [
    "for data in ws.datasets:\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad3ae130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'diabetes dataset' in ws.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "401dc715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\diabetes.csv', 'data\\\\diabetes2.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "# [os.path.join(root, f) for f in files for root, dirs, files in os.walk('data')]\n",
    "glob('data/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d04c92e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset already exist\n"
     ]
    }
   ],
   "source": [
    "# register dataset\n",
    "from azureml.core import Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "\n",
    "dataset_name = 'diabetes_dataset2'\n",
    "# if this dataset already registered, we will do nothing, otherwise, we upload the files, and register it.\n",
    "# if the file already uploaded, we will be notified, without re-uploading it again.\n",
    "if dataset_name not in ws.datasets: \n",
    "    print(\"We will upload the files to cloud datastore, retrive it and register it\")\n",
    "    Dataset.File.upload_directory(src_dir='data', target=DataPath(datastore, dataset_name)) \n",
    "    tab_data = Dataset.Tabular.from_delimited_files(path=(datastore, os.path.join(dataset_name, '*.csv')))\n",
    "    try:\n",
    "        tab_data = tab_data.register(workspace=ws,\n",
    "                                    name=dataset_name,\n",
    "                                    tags={\"format\": \"csv\"},\n",
    "                                    description=\"diabetes dataset\",\n",
    "                                    create_new_version=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print(\"dataset already exist\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0881652f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>PlasmaGlucose</th>\n",
       "      <th>DiastolicBloodPressure</th>\n",
       "      <th>TricepsThickness</th>\n",
       "      <th>SerumInsulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1354778</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>80</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>43.509726</td>\n",
       "      <td>1.213191</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1147438</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>21.240576</td>\n",
       "      <td>0.158365</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1640031</td>\n",
       "      <td>7</td>\n",
       "      <td>115</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>41.511523</td>\n",
       "      <td>0.079019</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1883350</td>\n",
       "      <td>9</td>\n",
       "      <td>103</td>\n",
       "      <td>78</td>\n",
       "      <td>25</td>\n",
       "      <td>304</td>\n",
       "      <td>29.582192</td>\n",
       "      <td>1.282870</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1424119</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>59</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>42.604536</td>\n",
       "      <td>0.549542</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1619297</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>92</td>\n",
       "      <td>9</td>\n",
       "      <td>253</td>\n",
       "      <td>19.724160</td>\n",
       "      <td>0.103424</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1660149</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>227</td>\n",
       "      <td>21.941357</td>\n",
       "      <td>0.174160</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1458769</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>87</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>18.277723</td>\n",
       "      <td>0.236165</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1201647</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>26.624929</td>\n",
       "      <td>0.443947</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1403912</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>36.889576</td>\n",
       "      <td>0.103944</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  Pregnancies  PlasmaGlucose  DiastolicBloodPressure  \\\n",
       "0    1354778            0            171                      80   \n",
       "1    1147438            8             92                      93   \n",
       "2    1640031            7            115                      47   \n",
       "3    1883350            9            103                      78   \n",
       "4    1424119            1             85                      59   \n",
       "5    1619297            0             82                      92   \n",
       "6    1660149            0            133                      47   \n",
       "7    1458769            0             67                      87   \n",
       "8    1201647            8             80                      95   \n",
       "9    1403912            1             72                      31   \n",
       "\n",
       "   TricepsThickness  SerumInsulin        BMI  DiabetesPedigree  Age  Diabetic  \n",
       "0                34            23  43.509726          1.213191   21         0  \n",
       "1                47            36  21.240576          0.158365   23         0  \n",
       "2                52            35  41.511523          0.079019   23         0  \n",
       "3                25           304  29.582192          1.282870   43         1  \n",
       "4                27            35  42.604536          0.549542   22         0  \n",
       "5                 9           253  19.724160          0.103424   26         0  \n",
       "6                19           227  21.941357          0.174160   21         0  \n",
       "7                43            36  18.277723          0.236165   26         0  \n",
       "8                33            24  26.624929          0.443947   53         1  \n",
       "9                40            42  36.889576          0.103944   26         0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a registered dataset from workspace\n",
    "ws.datasets.get(dataset_name).to_pandas_dataframe().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505e748a",
   "metadata": {},
   "source": [
    "### Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "174e727e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing playground/experiment_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_dir/experiment_env.yml\n",
    "name: experiment_env_2\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e6bca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "experiment_env = Environment.from_conda_specification(\"experiment_env_2\", script_dir + \"/experiment_env.yml\")\n",
    "\n",
    "# Register the environment \n",
    "experiment_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'experiment_env_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442bb180",
   "metadata": {},
   "source": [
    "### Prepare a compute instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8511aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"ComputerCluster\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32946624",
   "metadata": {},
   "source": [
    "### Setup the run config for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53b04729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5481796d",
   "metadata": {},
   "source": [
    "#### Define all the PythonScriptStep and intermediate data reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de6953cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\n",
    "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\n",
    "\n",
    "# Step 1, Run the data prep script\n",
    "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
    "                                source_directory = script_dir,\n",
    "                                script_name = \"prep_diabetes.py\",\n",
    "                                arguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\n",
    "                                             '--prepped-data', prepped_data],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "# Step 2, run the training script\n",
    "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
    "                                source_directory = script_dir,\n",
    "                                script_name = \"train_diabetes.py\",\n",
    "                                arguments = ['--training-data', prepped_data.as_input()],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d952bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_data.to_pandas_dataframe().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51323e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_dir/data_prep.py\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from azureml.core import Run\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
    "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
    "args = parser.parse_args()\n",
    "save_folder = args.prepped_data\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "diabetes = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
    "\n",
    "# Log raw row count\n",
    "row_count = (len(diabetes))\n",
    "run.log('raw_rows', row_count)\n",
    "\n",
    "# remove nulls\n",
    "diabetes = diabetes.dropna()\n",
    "\n",
    "# Normalize the numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "num_cols = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
    "diabetes[num_cols] = scaler.fit_transform(diabetes[num_cols])\n",
    "\n",
    "# Log processed rows\n",
    "row_count = len(diabetes)\n",
    "run.log('processed_rows', row_count)\n",
    "\n",
    "# Save the prepped data\n",
    "print(\"Saving Data...\")\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "save_path = os.path.join(save_folder,'data.csv')\n",
    "diabetes.to_csv(save_path, index=False, header=True)\n",
    "\n",
    "# End the run\n",
    "run.complete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
