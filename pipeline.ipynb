{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d2208e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Run, ScriptRunConfig\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.widgets import RunDetails\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "055f5d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = 'playground'\n",
    "os.makedirs(script_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eacf305a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing playground/data_prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_dir/data_prep.py\n",
    "import os\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "from sklearn.processing import MinMaxScaler\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--input_data', type=str, dest='raw_dataset', help='Raw dataset')\n",
    "parser.add_argument('--preped_data', type=str, dest='preped_dataset', help='Prepared dataset')\n",
    "args = parser.parse_args()\n",
    "\n",
    "saved_dir = args.preped_data\n",
    "run = Run.get_context()\n",
    "\n",
    "df = run.input_datasets['raw_dataset'].to_pandas_dataframe()\n",
    "\n",
    "num_features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure',\n",
    "                'TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
    "scaler = MinMaxScaler()\n",
    "df[num_features] = scaler.fit(df[num_features])\n",
    "\n",
    "print('saving data to preped_data')\n",
    "os.makedirs(saved_dir, exist_ok=True)\n",
    "df.to_csv(os.path.join(saved_dir, 'preped_data.csv'), index=False)\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0826cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing playground/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_dir/train.py\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import numpy as np\n",
    "from azureml.core import Run, Model\n",
    "import joblib\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--input_data', type=str, dest='input_data', help='Input dataset for model')\n",
    "args = parser.parse_args()\n",
    "\n",
    "run = Run.get_context()\n",
    "df = run.input_datsets['input_data'].to_pandas_dataframe()\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(df, test_size=.3, random_state=0)\n",
    "\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ACC\n",
    "acc = np.average(y_pred==y_test)\n",
    "run.log(name='acc', value=acc)\n",
    "\n",
    "# AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test, y_scores[:, 1])\n",
    "run.log(name='auc', value=auc)\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_score[:,1])\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.plot([0,1], [0,1], 'k--')\n",
    "ax.plot(fpr, tpr)\n",
    "ax.title('ROC curve')\n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "run.log_image(name='roc_curve', plot=fig)\n",
    "\n",
    "print('Saving model')\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "model_file_path = os.path.join('models', 'diabetes_model.pkl')\n",
    "joblib.dump(model, model_file_path)\n",
    "\n",
    "Model.register(workspace=ws,\n",
    "              model_path=model_file,\n",
    "              tags={\"training context\": \"pipeline\"},\n",
    "              properties={'AUC': auc, \"ACC\": acc},\n",
    "              model_Path=model_file_path)\n",
    "run.complete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff3675ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "datastore = ws.get_default_datastore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11adbf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch-data\n",
      "diabetes file dataset\n",
      "diabetes dataset\n",
      "loan_data\n"
     ]
    }
   ],
   "source": [
    "for data in ws.datasets:\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47e4eeed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'diabetes dataset' in ws.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f74c7e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\diabetes.csv', 'data\\\\diabetes2.csv']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "# [os.path.join(root, f) for f in files for root, dirs, files in os.walk('data')]\n",
    "glob('data/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d5c87dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will upload the files to cloud datastore, retrive it and register it\n",
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Uploading file to diabetes_dataset2\n",
      "Uploading an estimated of 2 files\n",
      "Target already exists. Skipping upload for diabetes_dataset2\\diabetes.csv\n",
      "Target already exists. Skipping upload for diabetes_dataset2\\diabetes2.csv\n",
      "Uploaded 0 files\n",
      "Creating new dataset\n"
     ]
    }
   ],
   "source": [
    "# register dataset\n",
    "from azureml.core import Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "\n",
    "dataset_name = 'diabetes_dataset2'\n",
    "\n",
    "if dataset_name not in ws.datasets:\n",
    "    print(\"We will upload the files to cloud datastore, retrive it and register it\")\n",
    "    Dataset.File.upload_directory(src_dir='data', target=DataPath(datastore, dataset_name)) \n",
    "    tab_data = Dataset.Tabular.from_delimited_files(path=(datastore, os.path.join(dataset_name, '*.csv')))\n",
    "    try:\n",
    "        tab_data = tab_data.register(workspace=ws,\n",
    "                                    name=dataset_name,\n",
    "                                    tags={\"format\": \"csv\"},\n",
    "                                    description=\"diabetes dataset\",\n",
    "                                    create_new_version=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print(\"dataset already exist\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ed1130b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'diabetes_dataset2\\\\*.csv')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"6227d552-254c-4db6-a0df-4f4db3249975\",\n",
       "    \"name\": \"diabetes_dataset2\",\n",
       "    \"version\": 1,\n",
       "    \"description\": \"diabetes dataset\",\n",
       "    \"tags\": {\n",
       "      \"format\": \"csv\"\n",
       "    },\n",
       "    \"workspace\": \"Workspace.create(name='myworkspace', subscription_id='efaef50b-3a01-4bf1-ad06-b63c101ab300', resource_group='resource-group-1')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_data.to_pandas_dataframe().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc886ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_dir/data_prep.py\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from azureml.core import Run\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
    "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
    "args = parser.parse_args()\n",
    "save_folder = args.prepped_data\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "diabetes = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
    "\n",
    "# Log raw row count\n",
    "row_count = (len(diabetes))\n",
    "run.log('raw_rows', row_count)\n",
    "\n",
    "# remove nulls\n",
    "diabetes = diabetes.dropna()\n",
    "\n",
    "# Normalize the numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "num_cols = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
    "diabetes[num_cols] = scaler.fit_transform(diabetes[num_cols])\n",
    "\n",
    "# Log processed rows\n",
    "row_count = len(diabetes)\n",
    "run.log('processed_rows', row_count)\n",
    "\n",
    "# Save the prepped data\n",
    "print(\"Saving Data...\")\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "save_path = os.path.join(save_folder,'data.csv')\n",
    "diabetes.to_csv(save_path, index=False, header=True)\n",
    "\n",
    "# End the run\n",
    "run.complete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
